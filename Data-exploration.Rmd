---
title: "Data exploration"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE, echo=FALSE}
rm(list=ls()) # Clears workspace
knitr::opts_chunk$set(warning=FALSE, message=FALSE, echo = TRUE)
knitr::opts_knit$set(progress=FALSE)

# Packages
PKG <- c("tidyverse","knitr", "renv", "modelsummary", "kableExtra", "corrplot","RColorBrewer","lmtest","sandwich","pscl", "glmmTMB", "broom.mixed","vcd") 

for (p in PKG) {
  if(!require(p,character.only = TRUE)) {  
    install.packages(p)
    require(p,character.only = TRUE)}
}
rm(PKG,p)
# install.packages("countreg", repos="http://R-Forge.R-project.org")
# library(countreg)
renv::snapshot()
```

## Analysis summary

This work estimates the effect of different sea-level rise adaptation strategies on adjacent recreation on the shoreline in California. This employs correlational regression methods, using geotagged social media data as a proxy for relative visitation to coastal areas alongside the primary adaptation strategy predictors and other relevant geospatial covariates. 

Traditionally engineered structures, as well as natural and nature-based features, can provide flood and erosion defense from coastal storms and sea level rise; however, a comprehensive understanding of the full suite of benefits of these strategies is necessary to understand the overall merits of different approaches. We present research investigating the differential effect of various shoreline protection strategies on recreation. Recreation is a vital contributor to coastal economies and social welfare in coastal communities that relies critically on the condition of the shoreline. 

Visitation is proxied via geotagged social media data from Flickr and Twitter. These are measured as average annual user days, from 2005 - 2017 for Flickr and 2012 - 2017 for Twitter. Values are extracted for cells within a hexagonal tessalation that intersect with the NOAA Environmental Sensitivity Index polyline for the California coastline. The user day counts are treated as a proxy for relative visitation and are the dependent variable in the visitation model.  

*Given that we have count data, and lots of zeros, natural choices for regression are a poisson, negative binomial, zero-inflated negative binomial, or a hurdle model. How to choose between these?*

Zero-inflated doesn't refer to lots of zeros in the outcome variable, but an outcome variable that you would expect to have lots of zeros that are based on a different process than generates non-zero values. As such, even with lots of zeros, a zero inflated negative binomial model may not be appropriate versus a standard NB model if the zeros originate from the same date generating process as the non-zero values. Hurdle models are generally used for sequential decision making and may not be appropriate here, as the decision process to visit the shoreline is typically one step.

Let's first explore some summary statistics. 

```{r data, include=FALSE}
df<-read_csv("results.csv")
df<-df[complete.cases(df),] # drops a few observations where the precipitation and air temp rasters returned NAs due to inadequate coverage
# rescaling population to thousands and distances to km, to deal with model convergence issues
df$sumpop<-df$sumpop/1000
df$rdist<-df$rdist/1000
df$wtlddist<-df$wtlddist/1000
```

<style>
  td {
    padding: 40px;
  }
</style>

```{r zeros, echo=FALSE, results='asis'}
df$hres<-as.factor(df$hres)
f1<-datasummary((ud == 0) + (ud > 0) ~ (N=1) + Percent(),
            data = df[df$hres==250&df$source=="PUD",],fmt="%.0f", title = 'Flickr Resolution 250m')
f2<-datasummary((ud == 0) + (ud > 0) ~ (N=1) + Percent(),
            data = df[df$hres==500&df$source=="PUD",],fmt="%.0f", title = 'Flickr Resolution 500m')
f3<-datasummary((ud == 0) + (ud > 0) ~ (N=1) + Percent(),
            data = df[df$hres==1000&df$source=="PUD",],fmt="%.0f", title = 'Flickr Resolution 1000m')

knitr::kables(list(f1,f2,f3)) %>%
  kable_styling(position = "center", bootstrap_options = "none")

t1<-datasummary((ud == 0) + (ud > 0) ~ (N=1) + Percent(),
            data = df[df$hres==250&df$source=="TUD",],fmt="%.0f", title = 'Twitter Resolution 250m')
t2<-datasummary((ud == 0) + (ud > 0) ~ (N=1) + Percent(),
            data = df[df$hres==500&df$source=="TUD",],fmt="%.0f", title = 'Twitter Resolution 500m')
t3<-datasummary((ud == 0) + (ud > 0) ~ (N=1) + Percent(),
            data = df[df$hres==1000&df$source=="TUD",],fmt="%.0f", title = 'Twitter Resolution 1000m')

knitr::kables(list(t1,t2,t3)) %>%
  kable_styling(position = "center", bootstrap_options = "none")

rm(f1,f2,f3,t1,t2,t3,summaryname)

```

The data is characterized by a significant number of zeros, that increase as a percentage of the data at higher resolutions. Twitter data seems to produce more zeros than flickr data at all resolutions. 

```{r continuous, echo=FALSE}
datasummary((`Distance to nearest road (km)`=rdist ) + (`Population within 8 miles`=sumpop) + (`Distance to nearest wetland (km)`=wtlddist) + (`Mean annual precipitation (mm/yr)`=meanprec) + (`Mean air temp (C)`=meanat) + (`Mean sea surface temp (C)`=meanSST) ~ Mean + Median + SD + Histogram, data = df[df$hres==250,],fmt="%.2f", title = 'Continuous Predictors 250m')

datasummary((`Distance to nearest road (km)`=rdist ) + (`Population within 8 miles`=sumpop) + (`Distance to nearest wetland (km)`=wtlddist) + (`Mean annual precipitation (mm/yr)`=meanprec) + (`Mean air temp (C)`=meanat) + (`Mean sea surface temp (C)`=meanSST) ~ Mean + Median + SD + Histogram, data = df[df$hres==1000,],fmt="%.2f", title = 'Continuous Predictors 1000m')
```

Summary statistics are shown for all potential continuous predictors. There is little variation across resolutions, but note that the higher resolution observation picks up finer scale variation in the 'distance to X' variables.

```{r discrete, echo=FALSE}
# Filtering area of influence of amenities represented in Yourcoast database
df<-mutate_at(df, vars(BIKE_PATH,BOATING,BT_FACIL_T,CAMPGROUND,DSABLDACSS,FEE,FISHING,PARKING,PTH_BEACH,RESTROOMS,STRS_BEACH), list(~ ifelse(YCdist>1000, 0, .)))

d1<-datasummary((`Exposed rocky shore`=x1a ) + (`Exposed solid man-made structures`=x1b) + (`Exposed wave-cut platforms in bedrock`=x2a) + (`Fine-to-medium grain sand beaches`=x3a) + (`Scarps and steep slopes in sand`=x3b) + (`Coarse-grained sand beaches`=x4) + (`Mixed sand and gravel beaches`=x5) + (`Gravel beaches`=x6a) + (`Riprap`=x6b) + (`Exposed tidal flats`=x7) + (`Sheltered rocky shores`=x8a) + (`Sheltered man-made structures`=x8b) + (`Sheltered riprap`=x8c) + (`Sheltered tidal flat`=x9a) + (`Vegetated low riverine banks`=x9b) + (`Salt and brackish marshes`=x10a) + (`Bike path`=BIKE_PATH) + (`Boating`=BOATING) + (`Boating facilities`=BT_FACIL_T) + (`Campground`=CAMPGROUND) + (`Disabled Access`=DSABLDACSS) + (`Fee`=FEE) + (`Fishing`=FISHING) + (`Parking available`=PARKING) + (`Path to beach`=PTH_BEACH) + (`Restrooms`=RESTROOMS) + (`Stairs to beach`=STRS_BEACH) + (`SF Bay Water Trail`=WaterTrail) + (`SF Bay Trail`=BayTrail) ~ Mean + SD, data = df[df$hres==250,],fmt="%.2f", title = 'Binary Predictors 250m')
d2<-datasummary((`Exposed rocky shore`=x1a ) + (`Exposed solid man-made structures`=x1b) + (`Exposed wave-cut platforms in bedrock`=x2a) + (`Fine-to-medium grain sand beaches`=x3a) + (`Scarps and steep slopes in sand`=x3b) + (`Coarse-grained sand beaches`=x4) + (`Mixed sand and gravel beaches`=x5) + (`Gravel beaches`=x6a) + (`Riprap`=x6b) + (`Exposed tidal flats`=x7) + (`Sheltered rocky shores`=x8a) + (`Sheltered man-made structures`=x8b) + (`Sheltered riprap`=x8c) + (`Sheltered tidal flat`=x9a) + (`Vegetated low riverine banks`=x9b) + (`Salt and brackish marshes`=x10a) + (`Bike path`=BIKE_PATH) + (`Boating`=BOATING) + (`Boating facilities`=BT_FACIL_T) + (`Campground`=CAMPGROUND) + (`Disabled Access`=DSABLDACSS) + (`Fee`=FEE) + (`Fishing`=FISHING) + (`Parking available`=PARKING) + (`Path to beach`=PTH_BEACH) + (`Restrooms`=RESTROOMS) + (`Stairs to beach`=STRS_BEACH) + (`SF Bay Water Trail`=WaterTrail) + (`SF Bay Trail`=BayTrail) ~ Mean + SD, data = df[df$hres==1000,],fmt="%.2f", title = 'Binary Predictors 1000m')

knitr::kables(list(d1,d2)) %>%
  kable_styling(position = "center", bootstrap_options = "none")

d1<-datasummary((`# of ESI types`=types) ~ Mean + SD, data = df[df$hres==250,],fmt="%.2f", title = 'ESI Types 250m')
d2<-datasummary((`# of ESI types`=types) ~ Mean + SD, data = df[df$hres==1000,],fmt="%.2f", title = 'ESI Types 1000m')

knitr::kables(list(d1,d2)) %>%
  kable_styling(position = "center", bootstrap_options = "none")

```

These values represent proportions of observations intersecting with ESI types, or within 1km of amenities in the [California Coastal Commission Yourcoast database](https://www.coastal.ca.gov/YourCoast/#/map). Amenities do not change markedly between resolutions as they are based on intersection with a buffer (within 1km of Yourcoast geotagged location), but there are more ESI types per observation as the resolution gets coarser. 

```{r correlationESI, echo=FALSE, fig.align="center"}
cormat<-round(cor(df[,3:18]),2)
rownames(cormat)<-c("Exposed rocky shore (1a)","Exposed solid man-made structures (1b)","Exposed wave-cut platforms in bedrock (2a)","Fine-to-medium grain sand beaches (3a)","Scarps and steep slopes in sand (3b)","Coarse-grained sand beaches (4)","Mixed sand and gravel beaches (5)","Gravel beaches (6a)","Riprap (6b)","Exposed tidal flats (7)","Sheltered rocky shores (8a)","Sheltered man-made structures (8b)","Sheltered riprap (8c)","Sheltered tidal flat (9a)","Vegetated low riverine banks (9b)","Salt and brackish marshes (10a)")
colnames(cormat)<-c("1a","1b","2a","3a","3b","4","5","6a","6b","7","8a","8b","8c","9a","9b","10a")
corrplot(cormat, method = "color", type = "lower", col = brewer.pal(n=8, name = "RdBu"),tl.col = "black")
```

Correlogram of ESI types. Not much correlation, though tidal flats and marshes are often observed together.

```{r correlationYC, echo=FALSE, fig.align="center"}
cormat<- df[df$hres==1000,] %>%
  dplyr::select(sumpop,rdist,BIKE_PATH,BOATING,BT_FACIL_T,CAMPGROUND,DSABLDACSS,FEE,FISHING,PARKING,PTH_BEACH,RESTROOMS,STRS_BEACH,WaterTrail,BayTrail,wtlddist,meanprec,meanat,meanSST)
cormat<-round(cor(cormat),2)
# rownames(cormat)<-c("Exposed rocky shore (1a)","Exposed solid man-made structures (1b)","Exposed wave-cut platforms in bedrock (2a)","Fine-to-medium grain sand beaches (3a)","Scarps and steep slopes in sand (3b)","Coarse-grained sand beaches (4)","Mixed sand and gravel beaches (5)","Gravel beaches (6a)","Riprap (6b)","Exposed tidal flats (7)","Sheltered rocky shores (8a)","Sheltered man-made structures (8b)","Sheltered riprap (8c)","Sheltered tidal flat (9a)","Vegetated low riverine banks (9b)","Salt and brackish marshes (10a)")
# colnames(cormat)<-c("1a","1b","2a","3a","3b","4","5","6a","6b","7","8a","8b","8c","9a","9b","10a")
par(xpd = TRUE) # https://stackoverflow.com/questions/46331172/corrplot-margin-in-plot-window
corrplot(cormat, method = "color", type = "lower", col = brewer.pal(n=8, name = "RdBu"),tl.col = "black", tl.srt = 45, mar = c(2, 2, 2, 2))

```

Correlogram of other predictors. Relationships are stable across resolutions; the above plots correlations at 1000m resolution.

```{r `ESI crosswalk`, echo=FALSE}

df$RockyShore<-pmax(df$x1a,df$x2a,df$x6a,df$x8a)
df$SandyBeach<-pmax(df$x3a,df$x3b,df$x4,df$x5)
df$Marshes<-pmax(df$x9a,df$x9b,df$x10a)
df$Armored<-pmax(df$x1b,df$x6b,df$x8b,df$x8c)

d1<-datasummary((`Rocky shore`=RockyShore) + (`Sandy beach`=SandyBeach) + (`Marshes`=Marshes) + (`Armored`=Armored) ~ Mean + SD, data = df[df$hres==1000,],fmt="%.2f", title = 'Binary Predictors 1000m')
d2<-datasummary((`Rocky shore`=RockyShore) + (`Sandy beach`=SandyBeach) + (`Marshes`=Marshes) + (`Armored`=Armored) ~ Mean + SD, data = df[df$hres==500,],fmt="%.2f", title = 'Binary Predictors 500m')
d3<-datasummary((`Rocky shore`=RockyShore) + (`Sandy beach`=SandyBeach) + (`Marshes`=Marshes) + (`Armored`=Armored) ~ Mean + SD, data = df[df$hres==250,],fmt="%.2f", title = 'Binary Predictors 250m')

knitr::kables(list(d1,d2,d3)) %>%
  kable_styling(position = "center", bootstrap_options = "none")
```

A proposed crosswalk of ESI types to fewer shoreline classes: Rocky shore {1A, 2A, 6A, 8A}, Sandy beach {3A, 3B, 4, 5}, Marshes {9A, 9B, 10A}, Armored shore {1B, 6B, 8B, 8C}. Again, there are more ESI types per observation as the resolution gets coarser. 


```{r `regressions Poisson`, echo=FALSE}
models<-list()
models[['Flickr 250m']]<-glm(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==250,], family = poisson)
models[['Flickr 500m']]<-glm(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==500,], family = poisson)
models[['Flickr 1000m']]<-glm(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==1000,], family = poisson)
models[['Twitter 250m']]<-glm(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==250,], family = poisson)
models[['Twitter 500m']]<-glm(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==500,], family = poisson)
models[['Twitter 1000m']]<-glm(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==1000,], family = poisson)

msummary(models, stars = TRUE, title = "Poisson regressions, across resolutions and data source")

# coeftest(mod1, vcov = sandwich)

```

```{r `regressions quasiPoisson`, echo=FALSE}
models <- list()
models[['Flickr 250m']]<-glm(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==250,], family = quasipoisson)
models[['Twitter 250m']]<-glm(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==250,], family = quasipoisson)

msummary(models, stars = TRUE, title = "Quasi-Poisson regression, across data source at 250m", gof_omit = "AIC|BIC|Log.Lik")

# coeftest(mod1, vcov = sandwich)
```

```{r `regression NB`, echo=FALSE, results='hide',fig.keep='all'}
models <- list()
models[['Flickr 250m']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==250,], family = nbinom2)
models[['Flickr 500m']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==500,], family = nbinom2)
models[['Flickr 1000m']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==1000,], family = nbinom2)
models[['Twitter 250m']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==250,], family = nbinom2)
models[['Twitter 500m']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==500,], family = nbinom2)
models[['Twitter 1000m']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==1000,], family = nbinom2)


# cm<-c('(Intercept)'='Constant', 'Armored'='Armored','BIKE_PATH'='Bike path','Boating'='BOATING','Boating facilities'='BT_FACIL_T','Campground'='CAMPGROUND','Disabled Access'='DSABLDACSS','Fee'='FEE','Fishing'='FISHING','Parking available'='PARKING','Path to beach'='PTH_BEACH','Restrooms'='RESTROOMS','Stairs to beach'='STRS_BEACH','SF Bay Water Trail'='WaterTrail','SF Bay Trail'='BayTrail')

gm<-modelsummary::gof_map
gm$omit<-FALSE
rows<-data.frame("term"="Num.Obs","Flickr 250m"="27315","Flickr 500m"="12221","Flickr 1000m"="5449","Twitter 250m"="27315","Twitter 500m"="12221","Twitter 1000m"="5449")
attr(rows,"position")<-49

msummary(models, stars = TRUE, title = "Negative binomial regression across data source and resolution", add_rows = rows)

```

```{r `regression comparison flickr`, echo=FALSE}
invisible(glmmTMBControl(optCtrl=list(iter.max=1e4,eval.max=1e3))) 
models <- list()
models[['Poisson']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==250,], family = poisson)
models[['Quasi-Poisson']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==500,], family = nbinom1)
models[['Negative Binomial']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==1000,], family = nbinom2)

# # Separating the model into two processes for the zeros and the non-zeros does not converge  
# models[['Hurdle']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + rdist + sumpop + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==250,], family = "truncated_nbinom2", zi=~.)
# models[['Zero-inflated Negative Binomial']]<-zeroinfl(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="PUD"&df$hres==250,], dist = "negbin")

gm<-modelsummary::gof_map
gm$omit<-ifelse(gm$raw == "nobs"|gm$raw == "df.residual",TRUE,FALSE)
rows<-data.frame("term"="Num.Obs","Poisson"="27315","Quasi-Poisson"="27315","Negative Binomial"="27315")
attr(rows,"position")<-49

msummary(models, stars = TRUE, title = "Different regression approaches, Flickr User Days 250m resolution", gof_map = gm, add_rows = rows)
```

Models that treat this as a two-stage process (ZINB and hurdle) do not converge when using all predictors for both processes. However, from a theoretical perspective shoreline visitation choice is not typically treated as a two-stage process in random utility models of visitation. Furthermore, the choice to visit the beach, versus do other activities, likely does not rely on the predictors we have here.

```{r `regression comparison twitter`, echo=FALSE}
models <- list()
models[['Poisson']]<-glm(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==250,], family = poisson) # glmmTMB doesn't converge
models[['Quasi-Poisson']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==500,], family = nbinom1)
models[['Negative Binomial']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==1000,], family = nbinom2)
# Separating the model into two processes for the zeros and the non-zeros does converge, unlike for the Flickr data
# models[['Hurdle']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + rdist + sumpop + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==250,], family = "truncated_nbinom2", zi=~.)
# models[['Zero-inflated Negative Binomial']]<-glmmTMB(ud ~ RockyShore + SandyBeach + Marshes + Armored + sumpop + rdist + BIKE_PATH + BOATING + BT_FACIL_T + CAMPGROUND + DSABLDACSS + FEE + FISHING + PARKING + PTH_BEACH + RESTROOMS + STRS_BEACH + WaterTrail + BayTrail + wtlddist + meanprec + meanat + meanSST, data = df[df$source=="TUD"&df$hres==250,], zi = ~., family = nbinom2)


gm<-modelsummary::gof_map
gm$omit<-ifelse(gm$raw == "nobs"|gm$raw == "df.residual"|gm$raw == "deviance"|gm$raw == "df.null"|gm$raw == "sigma"|gm$raw == "null.deviance",TRUE,FALSE)
rows<-data.frame("term"="Num.Obs","Poisson"="27315","Quasi-Poisson"="27315","Negative Binomial"="27315")
attr(rows,"position")<-49

msummary(models, stars = TRUE, title = "Different regression approaches, Twitter User Days 250m resolution", gof_map = gm, add_rows = rows)
```
```{r}
vcd::rootogram(df[df$source=="TUD"&df$hres==250,"ud"], predict(models[['Poisson']]), scale = "raw")
vcd::rootogram(df[df$source=="TUD"&df$hres==250,"ud"], predict(models[['Quasi-Poisson']]), scale = "raw")
vcd::rootogram(df[df$source=="TUD"&df$hres==250,"ud"], predict(models[['Negative Binomial']]), scale = "raw")


```



Rootograms are a useful way to compare model selection between these two, as they assess [overdispersion](https://www.theanalysisfactor.com/poisson-or-negative-binomial-using-count-model-diagnostics-to-select-a-model/), a key selection criteria between the models.